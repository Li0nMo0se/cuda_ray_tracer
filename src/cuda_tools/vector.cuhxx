#include "vector.cuh"

namespace cuda_tools
{

/* Kernels used internally by the vector to handle device memory */
namespace
{
template <typename T>
__global__ static void _kernel_dealloc(T** const data, const int32_t size)
{
    for (int32_t i = 0; i < size; i++)
        delete data[i];
}

template <typename T, typename SubT, typename... Ts>
__global__ static void _kernel_add_object(T** const data, Ts... args)
{
    // Data is already at the location in which the new element is stored
    *data = new SubT{args...};
}
} // namespace

template <typename T>
Vector<T>::Vector()
    : Vector(begin_capacity)
{
}

template <typename T>
Vector<T>::Vector(int32_t capacity)
    : capacity_(capacity)
{
    realloc(capacity);
}

template <typename T>
void Vector<T>::free()
{
    if (data_)
    {
        cuda_safe_call(cudaDeviceSynchronize());
        _kernel_dealloc<<<1, 1>>>(data_, size_);
        cuda_safe_call(cudaFree(data_));
    }
}

template <typename T>
void Vector<T>::realloc(const int32_t new_capacity)
{
    if (!data_)
        cuda_safe_call(cudaMalloc((void**)&data_, sizeof(T*) * new_capacity));
    else
    {
        T** tmp;
        cuda_safe_call(cudaMalloc((void**)&tmp, sizeof(T*) * new_capacity));
        cuda_safe_call(cudaMemcpy(tmp,
                                  data_,
                                  sizeof(T*) * size_,
                                  cudaMemcpyDeviceToDevice));
        cuda_safe_call(cudaFree(data_));
        data_ = tmp;
    }
    capacity_ = new_capacity;
}

template <typename T>
template <typename SubT, typename... Ts>
void Vector<T>::emplace_back(Ts&&... args)
{
    _kernel_add_object<T, SubT>
        <<<1, 1>>>(&(data_[size_]), std::forward<Ts>(args)...);
    ++size_;

    // Upgrade the capacity
    if (size_ == capacity_)
        realloc(capacity_ * 2);
}

template <typename T>
__host__ __device__ inline int32_t Vector<T>::size_get() const
{
    return size_;
}

template <typename T>
__device__ inline const T& Vector<T>::operator[](const int32_t pos) const
{
    assert(pos < size_);
    return *(data_[pos]);
}

template <typename T>
__device__ inline T& Vector<T>::operator[](const int32_t pos)
{
    assert(pos < size_);
    return *(data_[pos]);
}

template <typename T>
const T** Vector<T>::back_get() const
{
    cuda_safe_call(cudaDeviceSynchronize());
    if (size_ == 0)
        return nullptr;
    T** res = new T*;
    cudaMemcpy(res, data_ + size_ - 1, sizeof(T*), cudaMemcpyDeviceToHost);
    return const_cast<const T**>(res);
}

} // namespace cuda_tools