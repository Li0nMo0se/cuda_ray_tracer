#include "vector.cuh"
#include <cassert>
#include <cstring>
#include <cuda_runtime.h>

namespace cuda_tools
{

/* Kernels used internally by the vector to handle device memory */
namespace
{
template <typename T>
__global__ static void _kernel_dealloc(T** const data, const int32_t size)
{
    for (int32_t i = 0; i < size; i++)
        delete data[i];
}

template <typename T, typename SubT, typename... Ts>
__global__ static void _kernel_emplace_object(T** const data, Ts... args)
{
    // Data is already at the location in which the new element is stored
    *data = new SubT{args...};
}

template <typename T, typename SubT>
__global__ static void _kernel_push_object(T** const data, const SubT& arg)
{
    // Data is already at the location in which the new element is stored
    *data = new SubT(arg);
}

} // namespace

template <typename T>
__device__ __host__ Vector<T>::Vector()
    : Vector(begin_capacity)
{
}

template <typename T>
__device__ __host__ Vector<T>::Vector(int32_t capacity)
    : capacity_(capacity)
{
    realloc(capacity);
}

template <typename T>
__device__ __host__ Vector<T>::~Vector()
{
    if (data_)
    {
        cudaDeviceSynchronize();
        _kernel_dealloc<<<1, 1>>>(data_, size_);
        cudaFree(data_);
    }
}

template <typename T>
__device__ __host__ Vector<T>::Vector(Vector& other)
    : Vector(std::move(other))
{
}

template <typename T>
__device__ __host__ Vector<T>::Vector(Vector&& other)
{
    cudaDeviceSynchronize();

    // Copy fields
    size_ = other.size_;
    capacity_ = other.capacity_;
    data_ = other.data_;

    // Empty other
    other.size_ = 0;
    other.capacity_ = 0;
    other.data_ = nullptr;
}

template <typename T>
__device__ __host__ void Vector<T>::realloc(const int32_t new_capacity)
{
    if (!data_)
        cudaMalloc((void**)&data_, sizeof(T*) * new_capacity);
    else
    {
        T** tmp;
        cudaMalloc((void**)&tmp, sizeof(T*) * new_capacity);
        std::memcpy(tmp, data_, sizeof(T*) * size_);
        cudaFree(data_);
        data_ = tmp;
    }
    capacity_ = new_capacity;
}

template <typename T>
template <typename SubT, typename... Ts>
void Vector<T>::emplace_back(Ts&&... args)
{
    _kernel_emplace_object<T, SubT>
        <<<1, 1>>>(&(data_[size_]), std::forward<Ts>(args)...);
    ++size_;

    // Upgrade the capacity
    if (size_ == capacity_)
        realloc(capacity_ * 2);
}

template <typename T>
__device__ __host__ inline int32_t Vector<T>::size_get() const
{
    return size_;
}

template <typename T>
__device__ __host__ inline const T&
Vector<T>::operator[](const int32_t pos) const
{
    assert(pos < size_);
    return *(data_[pos]);
}

template <typename T>
const T** Vector<T>::back_get() const
{
    cuda_safe_call(cudaDeviceSynchronize());
    if (size_ == 0)
        return nullptr;
    T** res = new T*;
    cuda_safe_call(
        cudaMemcpy(res, data_ + size_ - 1, sizeof(T*), cudaMemcpyDeviceToHost));
    return const_cast<const T**>(res);
}

} // namespace cuda_tools